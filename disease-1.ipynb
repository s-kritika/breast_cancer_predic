{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>concavity</th>\n",
       "      <th>concave_points</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>radius.2</th>\n",
       "      <th>texture.2</th>\n",
       "      <th>perimeter.2</th>\n",
       "      <th>area.2</th>\n",
       "      <th>smoothness.2</th>\n",
       "      <th>compactness.2</th>\n",
       "      <th>concavity.2</th>\n",
       "      <th>concave_points.2</th>\n",
       "      <th>symmetry.2</th>\n",
       "      <th>fractal_dimension.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>99</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>122</td>\n",
       "      <td>8</td>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>1184</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>9053</td>\n",
       "      <td>8</td>\n",
       "      <td>589</td>\n",
       "      <td>153</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20</td>\n",
       "      <td>57</td>\n",
       "      <td>17</td>\n",
       "      <td>77</td>\n",
       "      <td>132</td>\n",
       "      <td>9</td>\n",
       "      <td>1326</td>\n",
       "      <td>0</td>\n",
       "      <td>8474</td>\n",
       "      <td>...</td>\n",
       "      <td>5435</td>\n",
       "      <td>0</td>\n",
       "      <td>7339</td>\n",
       "      <td>3</td>\n",
       "      <td>398</td>\n",
       "      <td>74</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>69</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>130</td>\n",
       "      <td>1203</td>\n",
       "      <td>0</td>\n",
       "      <td>1096</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7869</td>\n",
       "      <td>4</td>\n",
       "      <td>585</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>615</td>\n",
       "      <td>0</td>\n",
       "      <td>4006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "      <td>77</td>\n",
       "      <td>58</td>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4956</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>3</td>\n",
       "      <td>445</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>1297</td>\n",
       "      <td>0</td>\n",
       "      <td>1003</td>\n",
       "      <td>...</td>\n",
       "      <td>7572</td>\n",
       "      <td>0</td>\n",
       "      <td>7813</td>\n",
       "      <td>5</td>\n",
       "      <td>438</td>\n",
       "      <td>94</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Diagnosis  radius  texture  perimeter  area  smoothness  compactness  \\\n",
       "0         M      17       99         10    38         122            8   \n",
       "1         M      20       57         17    77         132            9   \n",
       "2         M      19       69         21    25         130         1203   \n",
       "3         M      11       42         20    38          77           58   \n",
       "4         M      20       29         14    34         135            1   \n",
       "\n",
       "   concavity  concave_points  symmetry  ...  radius.2  texture.2  perimeter.2  \\\n",
       "0       1001               0      1184  ...        95          0         9053   \n",
       "1       1326               0      8474  ...      5435          0         7339   \n",
       "2          0            1096         0  ...         0       7869            4   \n",
       "3        386               1         0  ...         0       4956            1   \n",
       "4       1297               0      1003  ...      7572          0         7813   \n",
       "\n",
       "   area.2  smoothness.2  compactness.2  concavity.2  concave_points.2  \\\n",
       "0       8           589            153            4                 0   \n",
       "1       3           398             74            8                 0   \n",
       "2     585            94              3            0               615   \n",
       "3     156             3            445           27                23   \n",
       "4       5           438             94           44                 0   \n",
       "\n",
       "   symmetry.2  fractal_dimension.2  \n",
       "0        6399                    0  \n",
       "1        5225                    0  \n",
       "2           0                 4006  \n",
       "3           0                  911  \n",
       "4        1149                    0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "disease = pd.read_csv(\"data.csv\")\n",
    "disease.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##checking whether the data is balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "disease_counts = disease[\"Diagnosis\"].value_counts()\n",
    "temp_df = pd.DataFrame({\n",
    "    \"disease\": disease_counts.index,\n",
    "    \"counts\": disease_counts.values\n",
    "})\n",
    "#plt.figure(figsize =(18,8))\n",
    "#sns.barplot(x=\"disease\", y=\"counts\", data=temp_df)\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##encoding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "disease['Diagnosis'] = label_encoder.fit_transform(disease['Diagnosis'])\n",
    "#corr_matrix = disease.corr()\n",
    "#corr_matrix['Diagnosis'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##train_test_splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rows in train set: 455\n",
      " Rows in test set: 114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(disease, test_size=0.2, random_state=42)\n",
    "print(f\" Rows in train set: {len(train_set)}\\n Rows in test set: {len(test_set)}\\n\")\n",
    "disease = train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_set.shape[1])  # Features in the training data\n",
    "#print(test_set.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease = train_set.drop(\"Diagnosis\", axis=1)\n",
    "diagnosis = train_set[\"Diagnosis\"].copy()\n",
    "#print(disease.shape[1])  # Features in the training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##creating a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "my_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('scalar', StandardScaler())\n",
    "])\n",
    "disease_tr = my_pipe.fit_transform(disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression\n",
      "model performance for training set: \n",
      "accuracy: 0.9231\n",
      "f1 score: 0.9232\n",
      "precision: 0.8895\n",
      "recall: 0.9053\n",
      "roc_auc_score: 0.9194\n",
      "decision_tree\n",
      "model performance for training set: \n",
      "accuracy: 1.0000\n",
      "f1 score: 1.0000\n",
      "precision: 1.0000\n",
      "recall: 1.0000\n",
      "roc_auc_score: 1.0000\n",
      "random_forest\n",
      "model performance for training set: \n",
      "accuracy: 1.0000\n",
      "f1 score: 1.0000\n",
      "precision: 1.0000\n",
      "recall: 1.0000\n",
      "roc_auc_score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "#defining scoring metric for k-fold cross validation\n",
    "def cv_scoring(estimator, disease_tr,diagnosis):\n",
    "  return accuracy_score(diagnosis, estimator.predict(disease_tr))\n",
    "\n",
    "\n",
    "#selecting model\n",
    "models={\n",
    "    \"logistic_regression\": LogisticRegression(max_iter=1000,class_weight='balanced'),\n",
    "    \"decision_tree\": DecisionTreeClassifier(class_weight='balanced',),\n",
    "    \"random_forest\": RandomForestClassifier(class_weight='balanced', random_state=18)    \n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "  model = list(models.values())[i]\n",
    "  model.fit(disease_tr,diagnosis)\n",
    "\n",
    "#making predictions\n",
    "y_train_predict = model.predict(disease_tr)\n",
    "print(list(models.keys())[i])\n",
    "scores(diagnosis, y_train_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv_scoring' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[214], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(models))):\n\u001b[0;32m      2\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(models\u001b[38;5;241m.\u001b[39mvalues())[i]\n\u001b[1;32m----> 3\u001b[0m   cross_val_score(model, disease_tr, diagnosis, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[43mcv_scoring\u001b[49m())\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;28mprint\u001b[39m(model[i])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv_scoring' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(models))):\n",
    "  model = list(models.values())[i]\n",
    "  cross_val_score(model, disease_tr, diagnosis, cv=10, n_jobs=-1, scoring=cv_scoring())\n",
    "  print(\"==\"*30)\n",
    "  print(model[i])\n",
    "  print(f\"scores: {scores}\")\n",
    "  print(f\"mean scores: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##evaluation score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(ac_value, pred_value):\n",
    "    #evaluating training model\n",
    "    model_train_accuracy = accuracy_score(ac_value, pred_value)\n",
    "    model_train_f1 = f1_score(ac_value, pred_value, average='weighted')\n",
    "    model_train_precision = precision_score(ac_value, pred_value, zero_division=0)\n",
    "    model_train_recall = recall_score(ac_value, pred_value)\n",
    "    model_train_rocauc_score = roc_auc_score(ac_value, pred_value)\n",
    "\n",
    "    print(\"model performance for training set: \")\n",
    "    print(\"accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print(\"f1 score: {:.4f}\".format(model_train_f1))\n",
    "    print(\"precision: {:.4f}\".format(model_train_precision))\n",
    "    print(\"recall: {:.4f}\".format(model_train_recall))\n",
    "    print(\"roc_auc_score: {:.4f}\".format(model_train_rocauc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression\n",
      "model performance for training set: \n",
      "accuracy: 0.9474\n",
      "f1 score: 0.9474\n",
      "precision: 0.9302\n",
      "recall: 0.9302\n",
      "roc_auc_score: 0.9440\n",
      "decision_tree\n",
      "model performance for training set: \n",
      "accuracy: 1.0000\n",
      "f1 score: 1.0000\n",
      "precision: 1.0000\n",
      "recall: 1.0000\n",
      "roc_auc_score: 1.0000\n",
      "random_forest\n",
      "model performance for training set: \n",
      "accuracy: 1.0000\n",
      "f1 score: 1.0000\n",
      "precision: 1.0000\n",
      "recall: 1.0000\n",
      "roc_auc_score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "x_test = test_set.drop(\"Diagnosis\", axis=1)\n",
    "y_test = test_set[\"Diagnosis\"].copy()\n",
    "x_test_prepared = my_pipe.transform(x_test) \n",
    "for i in range(len(list(models))):\n",
    " model = list(models.values())[i]\n",
    " final_predictions = model.predict(x_test_prepared)\n",
    " print(list(models.keys())[i])\n",
    " scores(y_test, final_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 1\n",
      " 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 1\n",
      " 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(list(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
